# BERT_NER

    In the legal sphere, the reading and extraction of data from parts within a
    process can extend the period from the entry of the process until its
    conclusion. This task is currently performed by people, where the methodology
    consists of opening each document and, within its parts, extracting
    key information of those involved in that process. This process can be
    performed by machines, reducing manual labor and optimizing the time for
    data extraction. A model training was carried out
    BERT (\textit{Bidirectional Encoder Representations from Transformers}) pre
    trained for the Portuguese language, using a database aimed at
    legal texts made available by the computer science laboratory of the
    University of Brasilia. The model reached a \textit{F1 score} of 0.918 and
    an accuracy of 0.981. BERT proved to be a model with great potential,
    reaching a score above 90\% with just 3 generations of training.